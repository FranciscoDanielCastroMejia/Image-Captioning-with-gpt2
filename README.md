# Image Captioning using ViT

This program is based in this [repository](https://github.com/inuwamobarak/Image-captioning-ViT) by the autor inuwamobarak. It uses vision transformers for make a better caption of the image, in this program you donÂ´t have to train the model, beacuse you are using a pre trained model. Also in this program you will find techniques to classify the text using spaicy, and for make sentiment clasfication of the sentence generated by the caption, we use pipeline("sentiment-analysis") from transformers.

---
## Requirements 

I recomend to install the following libraries in the following order:

- python = 3.11
- pip install transformers
- conda install pytorch:pytorch
- conda install anaconda::pillow
- conda install anaconda::ipython
- conda install spacy-model-en_core_web_sm
- pip install chardet

---
## Code
### Importing libraries 
```python
import os
import spacy 
import numpy as np
from transformers import pipeline
#__________________________________________________
# Web links Handler
import requests
# Backend
import torch
# Image Processing
from PIL import Image
# Transformer and pre-trained Model
from transformers import VisionEncoderDecoderModel, ViTImageProcessor, GPT2TokenizerFast
# Managing loading processing
from tqdm import tqdm
# Assign available GPU
device = "cuda" if torch.cuda.is_available() else "cpu"

```
### Importing the pre-trained model 

```python
# ViT Encoder-Decoder Model
model = VisionEncoderDecoderModel.from_pretrained("nlpconnect/vit-gpt2-image-captioning").to(device)
# Corresponding ViT Tokenizer
tokenizer = GPT2TokenizerFast.from_pretrained("nlpconnect/vit-gpt2-image-captioning")
# Image processor
image_processor = ViTImageProcessor.from_pretrained("nlpconnect/vit-gpt2-image-captioning")
```

### Accesssing images from the web
In this project we can find two versions of the program, y one you can use images from a folder that i created, and the program will generate all the captions for images that are in that. The another program is made to generate captions of images from the internet. So the next part of the code is from the program that use urls of images from the internet. 

```python
import urllib.parse as parse
import os
# Verify url
def check_url(string):
    try:
        result = parse.urlparse(string)
        return all([result.scheme, result.netloc, result.path])
    except:
        return False

# Load an image
def load_image(image_path):
    if check_url(image_path):
        return Image.open(requests.get(image_path, stream=True).raw)
    elif os.path.exists(image_path):
        return Image.open(image_path)

```

### Function to make inference with the image

# Image inference

```python
def get_caption(model, image_processor, tokenizer, image_path):
    image = load_image(image_path)
    # Preprocessing the Image
    img = image_processor(image, return_tensors="pt").to(device)
    # Generating captions
    output = model.generate(**img)
    # decode the output
    caption = tokenizer.batch_decode(output, skip_special_tokens=True)[0]
    return caption

```



